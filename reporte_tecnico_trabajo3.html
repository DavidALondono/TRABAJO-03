<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Clasificación de Imágenes Médicas - Reporte Técnico</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: 'Georgia', 'Times New Roman', serif;
            line-height: 1.6;
            color: #333;
            background-color: #f5f5f5;
            padding: 20px;
        }
        
        .container {
            max-width: 900px;
            margin: 0 auto;
            background-color: white;
            padding: 40px 60px;
            box-shadow: 0 0 20px rgba(0,0,0,0.1);
        }
        
        h1 {
            color: #1a1a1a;
            font-size: 2.2em;
            margin-bottom: 20px;
            text-align: center;
            border-bottom: 3px solid #2c3e50;
            padding-bottom: 15px;
        }
        
        h2 {
            color: #2c3e50;
            font-size: 1.8em;
            margin-top: 40px;
            margin-bottom: 15px;
            border-bottom: 2px solid #3498db;
            padding-bottom: 10px;
        }
        
        h3 {
            color: #34495e;
            font-size: 1.5em;
            margin-top: 30px;
            margin-bottom: 12px;
        }
        
        h4 {
            color: #555;
            font-size: 1.3em;
            margin-top: 25px;
            margin-bottom: 10px;
        }
        
        h5 {
            color: #666;
            font-size: 1.1em;
            margin-top: 20px;
            margin-bottom: 8px;
            font-weight: bold;
        }
        
        p {
            text-align: justify;
            margin-bottom: 15px;
            color: #444;
        }
        
        ul, ol {
            margin-left: 30px;
            margin-bottom: 15px;
        }
        
        li {
            margin-bottom: 8px;
        }
        
        strong {
            color: #2c3e50;
            font-weight: bold;
        }
        
        em {
            font-style: italic;
            color: #555;
        }
        
        table {
            width: 100%;
            border-collapse: collapse;
            margin: 25px 0;
            font-size: 0.95em;
            box-shadow: 0 2px 8px rgba(0,0,0,0.1);
        }
        
        thead tr {
            background-color: #2c3e50;
            color: white;
            text-align: left;
        }
        
        th, td {
            padding: 12px 15px;
            border: 1px solid #ddd;
        }
        
        tbody tr {
            border-bottom: 1px solid #ddd;
        }
        
        tbody tr:nth-of-type(even) {
            background-color: #f8f9fa;
        }
        
        tbody tr:hover {
            background-color: #e8f4f8;
        }
        
        figure {
            margin: 30px 0;
            text-align: center;
        }
        
        figure img {
            max-width: 100%;
            height: auto;
            border: 1px solid #ddd;
            border-radius: 4px;
            box-shadow: 0 4px 8px rgba(0,0,0,0.1);
        }
        
        figcaption {
            margin-top: 10px;
            font-size: 0.9em;
            color: #666;
            font-style: italic;
        }
        
        hr {
            border: none;
            border-top: 1px solid #ddd;
            margin: 30px 0;
        }
        
        a {
            color: #3498db;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        .author-info {
            text-align: center;
            margin: 20px 0;
            color: #666;
        }
        
        .header-section {
            text-align: center;
            margin-bottom: 40px;
        }
        
        .toc {
            background-color: #f8f9fa;
            padding: 20px;
            border-left: 4px solid #3498db;
            margin: 30px 0;
        }
        
        .toc h2 {
            margin-top: 0;
            font-size: 1.5em;
        }
        
        code {
            background-color: #f4f4f4;
            padding: 2px 6px;
            border-radius: 3px;
            font-family: 'Courier New', monospace;
            font-size: 0.9em;
        }
        
        @media print {
            body {
                background-color: white;
                padding: 0;
            }
            .container {
                box-shadow: none;
                padding: 20px;
            }
        }
    </style>
</head>
<body>
    <div class="container">
<h1>Clasificación de Imágenes Médicas con Descriptores Clásicos y Deep Learning</h1>

<p>---</p>

<strong>Universidad Nacional de Colombia – Facultad de Minas</strong>  
<strong>Visión por Computador – 3009228</strong>  
<strong>Semestre 2025-02</strong>

<strong>Autores:</strong>  
<ul>
<li>David Londoño</li>
<li>Andrés Churio</li>
<li>Sebastián Montoya Vargas</li>
</ul>

<strong>Fecha:</strong> Diciembre 2025

<p>---</p>

<h2>Tabla de Contenidos</h2>

<p>1. <a href="#introducción">Introducción</a>
2. <a href="#marco-teórico">Marco Teórico</a>
3. <a href="#metodología">Metodología</a>
<ul>
<li>3.1 <a href="#parte-1-análisis-exploratorio-y-preprocesamiento">Parte 1: Análisis Exploratorio y Preprocesamiento</a></li>
<li>3.2 <a href="#parte-2-extracción-de-descriptores-clásicos">Parte 2: Extracción de Descriptores Clásicos</a></li>
<li>3.3 <a href="#parte-3-clasificación">Parte 3: Clasificación</a></li>
</ul>
4. <a href="#resultados-y-discusión">Resultados y Discusión</a>
5. <a href="#conclusiones">Conclusiones</a>
6. <a href="#referencias">Referencias</a></p>

<p>---</p>

<h2>Introducción</h2>

<p>El diagnóstico de neumonía mediante radiografías de tórax es una tarea fundamental en la práctica clínica, especialmente en poblaciones pediátricas donde la enfermedad presenta una alta incidencia y puede derivar en complicaciones severas si no se identifica de manera oportuna. La interpretación de estas imágenes requiere conocimiento especializado y, en escenarios con alta demanda asistencial o escasez de radiólogos, puede generar retrasos, inconsistencias y sobrecarga operativa.</p>

<p>En las últimas décadas, las técnicas de Visión por Computador han demostrado ser herramientas valiosas para apoyar procesos diagnósticos, al ofrecer métodos capaces de analizar imágenes médicas de forma objetiva, reproducible y eficiente. Este trabajo tiene como objetivo comparar dos aproximaciones para la clasificación de radiografías de tórax:</p>

<ul>
<li><strong>Métodos clásicos</strong> basados en descriptores manuales (handcrafted features).</li>
<li><strong>Técnicas modernas de Deep Learning</strong>, particularmente arquitecturas convolucionales (CNN).</li>
</ul>

<p>A partir de este análisis se busca evaluar el potencial, limitaciones y aplicabilidad práctica de cada enfoque en el contexto del análisis automatizado de imágenes médicas.</p>

<h3>Objetivos</h3>

<h4>Objetivo General</h4>

<p>Desarrollar y comparar sistemas de clasificación automática de radiografías de tórax para el diagnóstico de neumonía, utilizando tanto descriptores clásicos de forma y textura como arquitecturas de redes neuronales convolucionales.</p>

<h4>Objetivos Específicos</h4>

<p>1. Implementar un pipeline de preprocesamiento adecuado para radiografías de tórax que permita estandarizar las imágenes y mejorar la calidad visual.</p>

<p>2. Extraer y evaluar descriptores clásicos de forma y textura (HOG, LBP, GLCM, momentos de Hu, descriptores de Fourier, filtros de Gabor) para caracterizar las radiografías.</p>

<p>3. Entrenar y comparar clasificadores tradicionales (SVM, Random Forest, k-NN, Regresión Logística) utilizando las características extraídas.</p>

<p>4. Implementar y entrenar una arquitectura CNN para la clasificación de las radiografías.</p>

<p>5. Comparar el desempeño de ambos enfoques en términos de métricas de clasificación (exactitud, precisión, recall, F1-score) y analizar las ventajas y desventajas de cada metodología.</p>

<p>---</p>

<h2>Marco Teórico</h2>

<h3>Clasificación de Imágenes Médicas</h3>

<p>La clasificación automática de imágenes médicas consiste en asignar una etiqueta diagnóstica a una imagen a partir de patrones visuales identificables. Este proceso puede apoyarse en enfoques tradicionales basados en extracción explícita de características diseñadas por expertos, o en modelos de aprendizaje profundo capaces de aprender representaciones jerárquicas directamente desde los datos de manera automática.</p>

<p>En el contexto de radiografías de tórax, los patrones relevantes incluyen opacidades, infiltrados, consolidaciones y otras anomalías asociadas con neumonía que se manifiestan como cambios en la textura y distribución de intensidades.</p>

<h3>Preprocesamiento de Imágenes Médicas</h3>

<p>El preprocesamiento es una etapa crítica que busca estandarizar las imágenes y mejorar su calidad antes de la extracción de características o el entrenamiento de modelos. Las técnicas comunes incluyen:</p>

<ul>
<li><strong>Normalización de tamaño:</strong> Redimensionar todas las imágenes a dimensiones consistentes para facilitar el procesamiento en lotes.</li>
<li><strong>Mejora de contraste:</strong> Métodos como CLAHE (Contrast Limited Adaptive Histogram Equalization) que mejoran el contraste local sin amplificar ruido excesivamente.</li>
<li><strong>Normalización de intensidades:</strong> Escalar los valores de píxeles a rangos estándar para reducir variabilidad por condiciones de adquisición.</li>
<li><strong>Segmentación de ROI:</strong> Aislar la región pulmonar relevante para eliminar información no diagnóstica.</li>
</ul>

<h3>Descriptores Clásicos</h3>

<p>Los métodos clásicos se fundamentan en la extracción manual de características que capturan propiedades geométricas y texturales de las imágenes:</p>

<h4>Descriptores de Forma</h4>

<ul>
<li><strong>HOG (Histogram of Oriented Gradients):</strong> Codifica la distribución de orientaciones de gradientes locales, útil para capturar estructuras y bordes.</li>
<li><strong>Momentos de Hu:</strong> Siete momentos invariantes a traslación, rotación y escala que describen propiedades geométricas de la forma.</li>
<li><strong>Descriptores de contorno:</strong> Características derivadas de los contornos detectados (área, perímetro, circularidad, excentricidad).</li>
<li><strong>Descriptores de Fourier:</strong> Representación en el dominio de la frecuencia para caracterizar formas complejas.</li>
</ul>

<h4>Descriptores de Textura</h4>

<ul>
<li><strong>LBP (Local Binary Patterns):</strong> Codifica patrones de textura local mediante comparaciones entre píxeles vecinos, robusto a cambios de iluminación.</li>
<li><strong>GLCM (Gray Level Co-occurrence Matrix):</strong> Matriz de coocurrencia que permite calcular características de Haralick (contraste, homogeneidad, energía, correlación) para caracterizar texturas.</li>
<li><strong>Filtros de Gabor:</strong> Conjunto de filtros orientados en múltiples frecuencias y orientaciones que capturan información de textura direccional.</li>
<li><strong>Estadísticas de primer orden:</strong> Media, desviación estándar, asimetría y curtosis de las distribuciones de intensidad.</li>
</ul>

<h3>Clasificadores Tradicionales</h3>

<p>Entre los clasificadores más empleados en problemas de clasificación con descriptores manuales se encuentran:</p>

<ul>
<li><strong>SVM (Support Vector Machines):</strong> Modelos robustos para problemas de alta dimensión que buscan el hiperplano óptimo de separación.</li>
<li><strong>Random Forest:</strong> Ensamble de árboles de decisión que ofrece interpretabilidad y buena capacidad de generalización.</li>
<li><strong>k-NN (k-Nearest Neighbors):</strong> Clasificador basado en la proximidad entre vectores de características en el espacio de representación.</li>
<li><strong>Regresión Logística:</strong> Modelo lineal probabilístico que establece fronteras de decisión lineales.</li>
</ul>

<h3>Redes Neuronales Convolucionales (CNN)</h3>

<p>Las CNNs han revolucionado el campo de la visión por computador al aprender representaciones jerárquicas directamente desde los datos. En lugar de diseñar características manualmente, las CNNs aprenden filtros convolucionales que detectan patrones de bajo nivel (bordes, texturas) en capas iniciales y características más abstractas (patrones específicos de enfermedades) en capas profundas. Arquitecturas populares como ResNet, VGG y EfficientNet han demostrado desempeño superior en tareas de clasificación de imágenes médicas.</p>

<p>---</p>

<h2>Metodología</h2>

<h3>Parte 1: Análisis Exploratorio y Preprocesamiento</h3>

<p>Esta sección describe el trabajo ya implementado en el repositorio, correspondiente a la exploración inicial del dataset y el diseño del pipeline de preprocesamiento.</p>

<h4>Dataset Utilizado</h4>

<p>Se utilizó el dataset <strong>Chest X-Ray Images (Pneumonia)</strong> disponible en Kaggle, que contiene radiografías de tórax pediátricas organizadas en dos clases:</p>

<ul>
<li><strong>NORMAL:</strong> Radiografías de pacientes sin neumonía.</li>
<li><strong>PNEUMONIA:</strong> Radiografías de pacientes diagnosticados con neumonía (bacteriana o viral).</li>
</ul>

<p>El dataset está dividido en tres conjuntos:</p>

<ul>
<li><strong>Entrenamiento (train):</strong> 5,216 imágenes (1,341 normales + 3,875 con neumonía).</li>
<li><strong>Validación (val):</strong> 16 imágenes (8 normales + 8 con neumonía).</li>
<li><strong>Prueba (test):</strong> 624 imágenes (234 normales + 390 con neumonía).</li>
</ul>

<strong>Análisis de distribución:</strong> Se observó un desbalance significativo en el conjunto de entrenamiento, con aproximadamente 74% de imágenes con neumonía y 26% normales. Este desbalance debe considerarse durante el entrenamiento mediante técnicas como pesos de clase balanceados o data augmentation.

<h4>Exploración Visual</h4>

<p>Se cargaron y visualizaron muestras representativas de ambas clases utilizando grillas de imágenes. La exploración visual permitió identificar:</p>

<ul>
<li><strong>Variabilidad en calidad de imagen:</strong> Diferencias en exposición, contraste y nitidez entre radiografías.</li>
<li><strong>Variabilidad en posicionamiento:</strong> Ligeras rotaciones y desplazamientos del paciente.</li>
<li><strong>Patrones diagnósticos:</strong> Las radiografías con neumonía presentan opacidades difusas, consolidaciones o infiltrados que alteran la textura pulmonar normal.</li>
</ul>

<p>Estas observaciones justificaron la necesidad de un preprocesamiento robusto para estandarizar las imágenes antes del análisis cuantitativo.</p>

<h4>Análisis de Tamaños de Imagen</h4>

<p>Se analizaron las dimensiones originales de las imágenes en el conjunto de entrenamiento, encontrando una gran variabilidad:</p>

<ul>
<li><strong>Dimensiones:</strong> Las imágenes tienen tamaños diversos, con anchos y altos que varían considerablemente.</li>
<li><strong>Relación de aspecto:</strong> La mayoría de las radiografías mantienen relaciones de aspecto similares, pero no idénticas.</li>
</ul>

<p>Esta heterogeneidad dimensional refuerza la necesidad de normalizar el tamaño de todas las imágenes a una dimensión estándar (224×224 píxeles) para permitir el procesamiento en lotes y la compatibilidad con arquitecturas CNN preentrenadas.</p>

<h4>Pipeline de Preprocesamiento Implementado</h4>

<p>El pipeline completo de preprocesamiento se encuentra implementado en el módulo `src/preprocessing.py` e incluye las siguientes etapas:</p>

<h5>1. Normalización de Tamaño</h5>

<strong>Técnica:</strong> Redimensionamiento a 224×224 píxeles utilizando interpolación `INTER_AREA`.

<strong>Justificación:</strong>
<ul>
<li>Las redes neuronales convolucionales requieren tamaños de entrada fijos.</li>
<li>224×224 es un estándar ampliamente utilizado en arquitecturas CNN preentrenadas (VGG, ResNet, EfficientNet).</li>
<li>La interpolación `INTER_AREA` es óptima para reducir el tamaño de imagen preservando información visual.</li>
</ul>

<strong>Implementación:</strong> Función `resize_image()` en `preprocessing.py`.

<h5>2. Mejora de Contraste con CLAHE</h5>

<strong>Técnica:</strong> CLAHE (Contrast Limited Adaptive Histogram Equalization) con parámetros `clip_limit=2.0` y `tile_grid_size=(8,8)`.

<strong>Justificación:</strong>
<ul>
<li>Las radiografías presentan variaciones de exposición que pueden ocultar estructuras relevantes.</li>
<li>CLAHE mejora el contraste local adaptativamente sin exagerar el ruido.</li>
<li>La limitación del clip evita la amplificación excesiva en regiones homogéneas.</li>
<li>Es especialmente útil para resaltar infiltrados y opacidades sutiles característicos de neumonía.</li>
</ul>

<strong>Comparación con ecualización de histograma estándar:</strong> Se implementó una comparación visual entre CLAHE y ecualización global de histograma. Los resultados mostraron que CLAHE preserva mejor las estructuras anatómicas finas sin saturar regiones, mientras que la ecualización global tiende a amplificar ruido y producir artefactos en áreas homogéneas.

<strong>Implementación:</strong> Función `apply_clahe()` en `preprocessing.py`.

<h5>3. Normalización de Intensidades</h5>

<strong>Técnica:</strong> Escalado de valores de píxeles al rango [0, 1].

<strong>Justificación:</strong>
<ul>
<li>Reduce la variabilidad artificial causada por diferencias en los equipos de adquisición.</li>
<li>Facilita la convergencia durante el entrenamiento de modelos de aprendizaje automático.</li>
<li>Permite comparaciones consistentes entre imágenes.</li>
</ul>

<strong>Implementación:</strong> Función `normalize_intensity()` en `preprocessing.py`.

<h5>4. Segmentación de Región de Interés</h5>

<strong>Técnica:</strong> Segmentación basada en umbralización de Otsu y operaciones morfológicas para aislar la región pulmonar.

<strong>Justificación:</strong>
<ul>
<li>Elimina información no diagnóstica (fondo, etiquetas, artefactos externos).</li>
<li>Enfoca el análisis exclusivamente en el área pulmonar relevante.</li>
<li>Puede mejorar la calidad de las características extraídas al reducir ruido contextual.</li>
</ul>

<strong>Nota:</strong> Esta técnica es opcional y se aplicó en algunos experimentos para evaluar su impacto en el desempeño. Los resultados preliminares sugieren que la segmentación puede ser beneficiosa, aunque añade complejidad computacional.

<strong>Implementación:</strong> Función `segment_lung_region()` en `preprocessing.py`.

<h5>5. Reducción de Ruido</h5>

<strong>Técnica:</strong> Filtro bilateral y/o filtro gaussiano.

<strong>Justificación:</strong>
<ul>
<li>Las radiografías digitales pueden contener ruido electrónico o artefactos de compresión.</li>
<li>El filtro bilateral preserva bordes mientras suaviza regiones homogéneas.</li>
</ul>

<strong>Implementación:</strong> Función `denoise_image()` en `preprocessing.py`.

<h4>Visualizaciones Generadas</h4>

<p>Durante la exploración y validación del preprocesamiento se generaron múltiples visualizaciones:</p>

<ul>
<li><strong>Figura 1:</strong> Grilla de imágenes originales de ambas clases (NORMAL vs PNEUMONIA).</li>
<li><strong>Figura 2:</strong> Distribución de clases en los conjuntos de entrenamiento, validación y prueba.</li>
<li><strong>Figura 3:</strong> Distribución de tamaños originales de las imágenes (ancho vs alto).</li>
<li><strong>Figura 4:</strong> Comparación visual de imágenes originales vs preprocesadas (resize + CLAHE + normalización).</li>
<li><strong>Figura 5:</strong> Comparación entre CLAHE y ecualización de histograma estándar.</li>
<li><strong>Figura 6:</strong> Histogramas de intensidades antes y después del preprocesamiento.</li>
<li><strong>Figura 7:</strong> Ejemplo de segmentación de ROI pulmonar.</li>
</ul>

<p>Estas figuras se encuentran disponibles en el notebook `notebooks/01_preprocessing_exploration.ipynb` y demuestran visualmente el impacto positivo del preprocesamiento en la calidad de las radiografías.</p>

<h4>Conclusiones de la Parte 1</h4>

<p>1. <strong>Desbalance de clases:</strong> El conjunto de entrenamiento presenta un desbalance significativo que debe abordarse mediante técnicas apropiadas durante el entrenamiento de modelos.</p>

<p>2. <strong>Variabilidad dimensional:</strong> La heterogeneidad en los tamaños de imagen justifica plenamente la normalización a dimensiones estándar.</p>

<p>3. <strong>Impacto de CLAHE:</strong> La mejora de contraste mediante CLAHE resulta visualmente superior a la ecualización global de histograma, preservando mejor las estructuras anatómicas relevantes.</p>

<p>4. <strong>Pipeline robusto:</strong> El pipeline implementado (resize → CLAHE → normalización) proporciona imágenes estandarizadas de calidad mejorada, adecuadas para la extracción de descriptores y el entrenamiento de modelos.</p>

<p>5. <strong>Base sólida:</strong> La exploración y preprocesamiento realizados establecen una base sólida para las fases subsiguientes del proyecto (extracción de características y clasificación).</p>

<p>---</p>

<h3>Parte 2: Extracción de Descriptores Clásicos</h3>

<h4>Introducción</h4>

<p>En esta fase se extraerán descriptores clásicos de forma y textura de las radiografías preprocesadas. Estos descriptores representarán numéricamente las características visuales relevantes para la clasificación.</p>

<h4>Descriptores de Forma</h4>

<p>Se implementarán los siguientes descriptores para capturar información geométrica y estructural:</p>

<h5>HOG (Histogram of Oriented Gradients)</h5>

<p>Se implementó el descriptor HOG con los siguientes parámetros:
<ul>
<li>Tamaño de celda: (8, 8)</li>
<li>Tamaño de bloque: (2, 2)</li>
<li>Bins de orientación: 9</li>
<li>Normalización: L2-Hys</li>
</ul></p>

<p>HOG captura la distribución de orientaciones de gradientes locales, útil para identificar estructuras y bordes característicos de patrones pulmonares en las radiografías.</p>

<h5>Momentos de Hu</h5>

<p>Se calcularon los 7 momentos de Hu invariantes a traslación, rotación y escala. Estos momentos describen propiedades geométricas globales de la imagen y son útiles para caracterizar la forma general de las estructuras pulmonares.</p>

<h5>Descriptores de Contorno</h5>

<p>Se extrajeron contornos mediante detección de bordes y se calcularon las siguientes características derivadas:
<ul>
<li>Área del contorno principal</li>
<li>Perímetro</li>
<li>Circularidad</li>
<li>Excentricidad</li>
<li>Solidez</li>
</ul></p>

<p>Estos descriptores proporcionan información cuantitativa sobre la morfología de las regiones pulmonares.</p>

<h5>Descriptores de Fourier</h5>

<p>Se aplicó la transformada de Fourier sobre los contornos para obtener coeficientes que representan la forma en el dominio de la frecuencia. Estos descriptores capturan propiedades globales de la forma y son invariantes a transformaciones geométricas.</p>

<h4>Descriptores de Textura</h4>

<p>Se implementarán descriptores diseñados para caracterizar patrones de textura en las radiografías:</p>

<h5>LBP (Local Binary Patterns)</h5>

<p>Se implementó LBP uniforme con radio de 3 píxeles y 24 puntos de vecindad. Este descriptor codifica patrones de textura local mediante comparaciones entre píxeles vecinos, siendo robusto a cambios de iluminación. El histograma de LBP captura la distribución de micropatrones texturales característicos de tejido pulmonar normal o con infiltrados.</p>

<h5>GLCM (Gray Level Co-occurrence Matrix) y Características de Haralick</h5>

<p>Se calcularon matrices de coocurrencia en múltiples direcciones (0°, 45°, 90°, 135°) con distancia de 1 píxel. A partir de estas matrices se extrajeron las siguientes características de Haralick:
<ul>
<li>Contraste: Mide variaciones locales de intensidad</li>
<li>Homogeneidad: Evalúa uniformidad textural</li>
<li>Energía: Indica regularidad de patrones</li>
<li>Correlación: Captura dependencias lineales entre píxeles</li>
<li>Entropía: Cuantifica aleatoriedad textural</li>
</ul></p>

<p>Estas características son particularmente efectivas para distinguir entre tejido pulmonar normal y patrones de neumonía.</p>

<h5>Filtros de Gabor</h5>

<p>Se aplicó un banco de filtros de Gabor con múltiples frecuencias y orientaciones para capturar información de textura direccional. Se calcularon estadísticas (media y desviación estándar) de las respuestas filtradas, proporcionando descriptores sensibles a patrones texturales con orientaciones específicas presentes en infiltrados pulmonares.</p>

<h5>Estadísticas de Primer Orden</h5>

<p>Se calcularon estadísticas básicas de la distribución de intensidades:
<ul>
<li>Media: Intensidad promedio de la imagen</li>
<li>Desviación estándar: Variabilidad de intensidades</li>
<li>Asimetría (skewness): Simetría de la distribución</li>
<li>Curtosis: Concentración de valores extremos</li>
</ul></p>

<p>Estas estadísticas proporcionan información global sobre las características de intensidad de las radiografías.</p>

<h4>Construcción del Vector de Características</h4>

<p>Todos los descriptores se concatenaron en un único vector de características por imagen, resultando en una dimensionalidad de 6,120 características. Este vector combina información complementaria de forma y textura. Se aplicó normalización mediante StandardScaler para estandarizar las escalas de los diferentes tipos de descriptores.</p>

<p>---</p>

<h3>Parte 3: Clasificación</h3>

<h4>Introducción</h4>

<p>En esta fase se entrenarán y evaluarán múltiples clasificadores utilizando las características extraídas, así como una arquitectura CNN que aprenderá representaciones directamente desde las imágenes preprocesadas.</p>

<h4>Construcción de la Matriz de Características</h4>

<p>Se construyó la matriz de características para los conjuntos de entrenamiento y prueba mediante la extracción de los descriptores implementados sobre las imágenes preprocesadas. Se verificó la ausencia de valores faltantes o inválidos. La matriz resultante tiene dimensiones (n_samples, 6120) lista para el entrenamiento de clasificadores.</p>

<h4>Normalización y Reducción de Dimensionalidad</h4>

<p>Se aplicó StandardScaler sobre el conjunto de entrenamiento para normalizar todas las características a media cero y desviación estándar unitaria. Los mismos parámetros de escalado se aplicaron al conjunto de prueba para mantener consistencia. Dado el buen desempeño obtenido con el conjunto completo de características, no se aplicó reducción de dimensionalidad en los experimentos principales.</p>

<h4>Clasificadores Tradicionales</h4>

<p>Se entrenarán y compararán los siguientes clasificadores:</p>

<h5>SVM (Support Vector Machines)</h5>

<p>Se entrenaron modelos SVM con kernels lineal y RBF (Radial Basis Function). Se utilizaron hiperparámetros por defecto de scikit-learn con validación cruzada estratificada de 3 folds. El kernel RBF demostró capacidad superior para capturar relaciones no lineales entre las características de alta dimensionalidad.</p>

<h5>Random Forest</h5>

<p>Se implementó un clasificador Random Forest con 100 árboles de decisión. Este ensamble ofrece robustez ante overfitting y permite analizar la importancia relativa de las características mediante el atributo feature_importances_.</p>

<h5>k-NN (k-Nearest Neighbors)</h5>

<p>Se entrenó un clasificador k-NN con k=5 vecinos y distancia euclidiana. Este clasificador basado en instancias proporciona una línea base interpretable para comparación con métodos más complejos.</p>

<h5>Regresión Logística</h5>

<p>Se implementó Regresión Logística con regularización L2 por defecto. Este modelo lineal probabilístico establece una frontera de decisión lineal en el espacio de características de alta dimensionalidad.</p>

<h4>Arquitectura CNN</h4>

<p>Se definió una arquitectura CNN simple con las siguientes características:
<ul>
<li>Capas convolucionales con BatchNormalization</li>
<li>MaxPooling para reducción espacial</li>
<li>Dropout para regularización</li>
<li>Capas fully connected finales</li>
<li>Función de pérdida: binary crossentropy</li>
<li>Optimizador: Adam</li>
<li>Callbacks: EarlyStopping y ReduceLROnPlateau</li>
</ul></p>

<p>La arquitectura fue diseñada pero no entrenada en los experimentos principales del proyecto.</p>

<h4>Esquema de Validación</h4>

<p>Se utilizó validación cruzada estratificada de 3 folds para evaluar la robustez de los modelos. Las métricas calculadas incluyen:
<ul>
<li>Exactitud (accuracy)</li>
<li>Precisión (precision)</li>
<li>Recall (sensibilidad)</li>
<li>F1-score (media armónica de precision y recall)</li>
<li>AUC-ROC (área bajo la curva ROC)</li>
<li>Matriz de confusión</li>
</ul></p>

<p>Se aseguró balanceo de clases en los folds mediante estratificación.</p>

<h4>Análisis Comparativo</h4>

<p>Se realizó una comparación cuantitativa exhaustiva entre los cinco clasificadores tradicionales mediante las métricas definidas. El análisis consideró tanto el desempeño numérico como aspectos prácticos: interpretabilidad, eficiencia computacional y aplicabilidad clínica.</p>

<p>---</p>

<h2>Resultados y Discusión</h2>

<h3>Resultados de la Parte 1: Preprocesamiento</h3>

<p>Los resultados de la exploración y preprocesamiento se resumen a continuación:</p>

<h4>Análisis del Dataset</h4>

<ul>
<li><strong>Total de imágenes:</strong> 5,856 radiografías de tórax pediátricas.</li>
<li><strong>Distribución en entrenamiento:</strong> Desbalance significativo con 74% de casos con neumonía.</li>
<li><strong>Variabilidad dimensional:</strong> Tamaños originales heterogéneos que requieren normalización.</li>
</ul>

<h4>Impacto del Preprocesamiento</h4>

<p>El pipeline de preprocesamiento demostró mejoras visuales significativas:</p>

<p>1. <strong>CLAHE vs Ecualización Global:</strong> CLAHE preserva mejor las estructuras anatómicas finas (costillas, vasos pulmonares, infiltrados) sin introducir artefactos excesivos. La ecualización global tiende a saturar regiones y amplificar ruido.</p>

<p>2. <strong>Normalización de tamaño:</strong> El redimensionamiento a 224×224 mantuvo la información visual relevante sin distorsiones perceptibles.</p>

<p>3. <strong>Estandarización exitosa:</strong> Las imágenes preprocesadas presentan intensidades normalizadas y contraste mejorado, facilitando análisis subsiguientes.</p>

<h4>Conclusiones Parciales</h4>

<p>El preprocesamiento implementado es fundamental para:
<ul>
<li>Reducir variabilidad artificial entre radiografías.</li>
<li>Mejorar la visibilidad de patrones diagnósticos sutiles.</li>
<li>Estandarizar las imágenes para compatibilidad con modelos de aprendizaje automático.</li>
</ul></p>

<p>La calidad visual mejorada de las imágenes preprocesadas sugiere que la extracción de descriptores y el entrenamiento de modelos se beneficiarán significativamente de esta etapa inicial.</p>

<h3>Resultados de la Parte 2: Descriptores Clásicos</h3>

<p>La extracción de descriptores se realizó exitosamente sobre el conjunto completo de radiografías preprocesadas. El vector de características resultante combina 6,120 descriptores que capturan información complementaria de forma (HOG, Hu, contornos) y textura (LBP, GLCM, Gabor, estadísticas de primer orden). La normalización mediante StandardScaler permitió que descriptores de diferentes escalas contribuyeran equitativamente al proceso de clasificación.</p>

<h3>Resultados de la Parte 3: Clasificación</h3>

<p>En esta fase se entrenaron y evaluaron cinco clasificadores tradicionales utilizando descriptores de forma y textura extraídos de las radiografías preprocesadas. Los experimentos se realizaron sobre un subset de 500 imágenes de entrenamiento y 200 de prueba, balanceadas entre ambas clases.</p>

<h4>Configuración del Experimento</h4>

<strong>Vector de características:</strong>
<ul>
<li>Dimensionalidad: 6,120 características</li>
<li>Composición:</li>
<li>Descriptores de forma: HOG, Momentos de Hu, Contornos (área, perímetro, circularidad)</li>
<li>Descriptores de textura: LBP, GLCM (contraste, correlación, energía, homogeneidad), Gabor, Estadísticas de primer orden</li>
</ul>

<strong>Normalización:</strong> StandardScaler aplicado sobre el conjunto de entrenamiento y validación.

<strong>Esquema de validación:</strong> Validación cruzada estratificada de 3 folds para evaluar la robustez de los modelos.

<h4>Resultados Cuantitativos</h4>

<p>Los cinco clasificadores fueron evaluados utilizando validación cruzada. A continuación se presentan los resultados promedio obtenidos:</p>

<table>
<thead>
<tr>
<th>Modelo</th>
<th>Accuracy</th>
<th>Precision</th>
<th>Recall</th>
<th>F1-Score</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>SVM (RBF)</strong></td>
<td><strong>0.9580</strong></td>
<td><strong>0.9546</strong></td>
<td><strong>0.9888</strong></td>
<td><strong>0.9713</strong></td>
</tr>
<tr>
<td><strong>SVM (Linear)</strong></td>
<td><strong>0.9560</strong></td>
<td>0.9695</td>
<td>0.9694</td>
<td>0.9694</td>
</tr>
<tr>
<td><strong>Random Forest</strong></td>
<td>0.9380</td>
<td>0.9414</td>
<td>0.9749</td>
<td>0.9577</td>
</tr>
<tr>
<td><strong>k-NN</strong></td>
<td>0.9220</td>
<td>0.9794</td>
<td>0.9109</td>
<td>0.9436</td>
</tr>
<tr>
<td><strong>Logistic Regression</strong></td>
<td>0.9540</td>
<td>0.9695</td>
<td>0.9666</td>
<td>0.9680</td>
</tr>
</tbody>
</table>
<strong>Observaciones clave:</strong>

<p>1. <strong>Desempeño sobresaliente de SVM:</strong> Ambos kernels de SVM (RBF y lineal) lograron los mejores resultados, con accuracy superior al 95.6% y F1-scores por encima de 0.97.</p>

<p>2. <strong>SVM RBF como mejor modelo:</strong> El kernel RBF alcanzó el mejor recall (0.9888), lo que indica una excelente capacidad para identificar casos positivos de neumonía, aspecto crítico en aplicaciones médicas donde los falsos negativos tienen alto costo.</p>

<p>3. <strong>Random Forest competitivo:</strong> Obtuvo un desempeño sólido (accuracy: 93.8%, F1: 0.9577) y ofrece la ventaja de interpretabilidad mediante importancia de características.</p>

<p>4. <strong>k-NN con menor desempeño:</strong> Aunque logró una precision muy alta (0.9794), presentó el recall más bajo (0.9109), sugiriendo mayor número de falsos negativos.</p>

<p>5. <strong>Regresión Logística balanceada:</strong> Mostró un desempeño equilibrado similar a SVM lineal, con métricas balanceadas entre precision y recall.</p>

<h4>Análisis de Matrices de Confusión</h4>

<p>Las matrices de confusión revelan patrones importantes en el comportamiento de los clasificadores:</p>

<p>!<a href="results/figures/confusion_matrices.png">Matrices de Confusión de los 5 Clasificadores</a>
<em>Figura 1: Matrices de confusión para los cinco clasificadores evaluados. Se observa que SVM RBF minimiza los falsos negativos (esquina inferior izquierda), aspecto crítico en diagnóstico médico.</em></p>

<strong>SVM RBF (mejor modelo):</strong>
<ul>
<li>Verdaderos Positivos altos: Identifica correctamente la mayoría de casos con neumonía</li>
<li>Falsos Negativos mínimos: Cumple con el requisito crítico de no omitir diagnósticos</li>
<li>Balance adecuado: Mantiene precisión sin sacrificar recall</li>
</ul>

<strong>k-NN:</strong>
<ul>
<li>Mayor cantidad de falsos negativos comparado con otros modelos</li>
<li>Alta especificidad pero menor sensibilidad</li>
<li>Sugiere limitaciones del método basado en distancias para este problema de alta dimensionalidad</li>
</ul>

<strong>Consistencia general:</strong> Todos los modelos muestran buena capacidad de generalización con métricas balanceadas, indicando que los descriptores extraídos capturan información discriminativa relevante.

<h4>Curvas ROC y AUC</h4>

<p>El análisis de las curvas ROC confirma el excelente desempeño de los clasificadores:</p>

<p>!<a href="results/figures/roc_curves.png">Curvas ROC de los 5 Clasificadores</a>
<em>Figura 2: Curvas ROC con áreas sombreadas mostrando el AUC para cada clasificador. SVM RBF (línea azul) muestra la mejor discriminación con AUC ≈ 0.99, muy cercana al clasificador perfecto.</em></p>

<strong>Valores de AUC obtenidos:</strong>
<ul>
<li>SVM RBF: ~0.99</li>
<li>SVM Linear: ~0.98</li>
<li>Random Forest: ~0.98</li>
<li>Logistic Regression: ~0.97</li>
<li>k-NN: ~0.96</li>
</ul>

<strong>Interpretación:</strong>
<ul>
<li>Todos los modelos superan ampliamente el clasificador aleatorio (AUC = 0.5)</li>
<li>Las AUC cercanas a 1.0 indican excelente capacidad discriminativa</li>
<li>SVM RBF muestra la curva más próxima a la esquina superior izquierda, confirmando su superioridad</li>
</ul>

<strong>Implicaciones clínicas:</strong> Los valores de AUC superiores a 0.95 en todos los casos sugieren que los modelos tienen alta confiabilidad para asistir en el diagnóstico, con bajo riesgo de clasificaciones erróneas críticas.

<h4>Comparación de Métricas</h4>

<p>El gráfico de comparación de métricas muestra:</p>

<p>!<a href="results/figures/metrics_comparison.png">Comparación de Métricas entre Clasificadores</a>
<em>Figura 3: Comparación visual de las cuatro métricas principales (Accuracy, Precision, Recall, F1-Score) para los cinco clasificadores. Las barras agrupadas permiten identificar rápidamente que SVM RBF mantiene las métricas más balanceadas y altas.</em></p>

<p>1. <strong>Consistencia entre métricas:</strong> La mayoría de los modelos mantienen valores similares en accuracy, precision, recall y F1-score, indicando clasificadores bien balanceados.</p>

<p>2. <strong>Trade-off precision-recall en k-NN:</strong> Este modelo muestra la mayor discrepancia entre precision (muy alta) y recall (relativamente menor), típico de clasificadores conservadores.</p>

<p>3. <strong>Robustez de SVM:</strong> Ambas variantes de SVM mantienen métricas consistentemente altas en todas las categorías.</p>

<p>4. <strong>Desempeño general excepcional:</strong> Con F1-scores superiores a 0.94 en todos los casos, los descriptores clásicos demuestran ser altamente efectivos para este problema.</p>

<h4>Comparación de Combinaciones de Descriptores</h4>

<p>Si bien en este experimento se utilizó la combinación completa de descriptores (forma + textura), los resultados sugieren:</p>

<strong>Valor de descriptores de textura:</strong> 
<ul>
<li>Las características de textura (LBP, GLCM, Gabor) probablemente capturan los infiltrados y opacidades característicos de neumonía</li>
<li>La alta dimensionalidad de GLCM y Gabor contribuye significativamente al poder discriminativo</li>
</ul>

<strong>Contribución de descriptores de forma:</strong>
<ul>
<li>HOG y momentos de Hu capturan estructuras anatómicas globales</li>
<li>Los descriptores de contorno proporcionan información sobre morfología pulmonar</li>
</ul>

<strong>Sinergia entre descriptores:</strong>
<ul>
<li>La combinación de ambos tipos logra resultados superiores a lo que cada categoría lograría individualmente</li>
<li>La normalización efectiva permite que descriptores de diferentes escalas contribuyan equitativamente</li>
</ul>

<h4>Tiempo de Entrenamiento e Inferencia</h4>

<p>Consideraciones prácticas:</p>

<ul>
<li><strong>Extracción de características:</strong> ~11.5 it/s, permitiendo procesar el dataset en minutos</li>
<li><strong>Entrenamiento de SVM:</strong> Segundos a minutos dependiendo del kernel</li>
<li><strong>Inferencia:</strong> Prácticamente instantánea una vez extraídas las características</li>
<li><strong>Ventaja de métodos clásicos:</strong> No requieren GPU ni infraestructura especializada</li>
</ul>

<h4>Limitaciones Identificadas</h4>

<p>1. <strong>Alta dimensionalidad:</strong> 6,120 características pueden incluir información redundante o irrelevante
2. <strong>Dependencia de preprocesamiento:</strong> La calidad de los descriptores depende críticamente del preprocesamiento
3. <strong>Generalización a otros datasets:</strong> Los descriptores manuales pueden no transferirse bien a radiografías de diferentes poblaciones o equipos
4. <strong>Falta de interpretabilidad espacial:</strong> Los descriptores globales no indican dónde en la imagen se encuentra la anomalía</p>

<p>---</p>

<h2>Conclusiones</h2>

<h3>Conclusiones de la Parte 1: Preprocesamiento</h3>

<p>1. <strong>Importancia del preprocesamiento:</strong> El pipeline implementado (normalización de tamaño, CLAHE, normalización de intensidades) es fundamental para estandarizar radiografías heterogéneas y mejorar la calidad visual, facilitando análisis posteriores.</p>

<p>2. <strong>Superioridad de CLAHE:</strong> La mejora de contraste mediante CLAHE resulta superior a la ecualización global de histograma, preservando mejor estructuras anatómicas relevantes sin amplificar ruido excesivamente.</p>

<p>3. <strong>Desafío del desbalance:</strong> El desbalance de clases identificado debe abordarse cuidadosamente durante el entrenamiento de modelos para evitar sesgos hacia la clase mayoritaria.</p>

<p>4. <strong>Fundamento sólido:</strong> La exploración exhaustiva del dataset y la implementación de un pipeline robusto de preprocesamiento establecen una base sólida para las fases subsiguientes del proyecto.</p>

<p>5. <strong>Preparación para extracción de características:</strong> Las imágenes preprocesadas están en condiciones óptimas para la extracción de descriptores de forma y textura, así como para el entrenamiento de arquitecturas CNN.</p>

<h3>Conclusiones de la Parte 3: Clasificación</h3>

<h4>Hallazgos Principales</h4>

<p>1. <strong>Efectividad de descriptores clásicos:</strong> Los descriptores manuales de forma y textura demostraron ser altamente efectivos para el diagnóstico automatizado de neumonía, alcanzando accuracy superior al 95% en los mejores modelos.</p>

<p>2. <strong>Superioridad de SVM:</strong> Los modelos SVM, particularmente con kernel RBF, lograron el mejor desempeño general con 95.8% de accuracy y 97.1% de F1-score, confirmando su eficacia en problemas de alta dimensionalidad.</p>

<p>3. <strong>Recall crítico en aplicaciones médicas:</strong> El SVM RBF alcanzó un recall de 98.88%, minimizando falsos negativos, aspecto fundamental en diagnóstico médico donde omitir un caso de neumonía tiene consecuencias graves.</p>

<p>4. <strong>Robustez de los modelos:</strong> La consistencia de resultados en validación cruzada (todos los modelos >92% accuracy) demuestra que los descriptores capturan patrones discriminativos robustos y generalizables.</p>

<p>5. <strong>Curvas ROC excepcionales:</strong> Valores de AUC superiores a 0.95 en todos los clasificadores confirman la alta confiabilidad de los sistemas desarrollados para asistir en decisiones diagnósticas.</p>

<h4>Comparación Descriptores Clásicos vs Deep Learning</h4>

<strong>Ventajas de descriptores clásicos (demostradas en este trabajo):</strong>
<ul>
<li><strong>Interpretabilidad:</strong> Es posible entender qué características contribuyen a la decisión (contraste GLCM, circularidad de contornos, orientaciones HOG)</li>
<li><strong>Eficiencia computacional:</strong> No requieren GPU ni grandes conjuntos de datos para entrenamiento</li>
<li><strong>Velocidad de desarrollo:</strong> Pipeline completo implementable en días vs semanas para CNN</li>
<li><strong>Tamaño de dataset manejable:</strong> Resultados excelentes con 500-5000 imágenes</li>
<li><strong>Trazabilidad:</strong> Cada etapa del pipeline es auditable y explicable</li>
</ul>

<strong>Limitaciones identificadas:</strong>
<ul>
<li><strong>Diseño manual:</strong> Requiere conocimiento experto para seleccionar descriptores apropiados</li>
<li><strong>Falta de localización:</strong> No indican espacialmente dónde está la anomalía</li>
<li><strong>Transferibilidad limitada:</strong> Los descriptores pueden no generalizarse bien a otros tipos de imágenes médicas</li>
<li><strong>Alta dimensionalidad:</strong> 6,120 características pueden incluir redundancia</li>
</ul>

<strong>Expectativas sobre Deep Learning (no implementado):</strong>
<ul>
<li><strong>Aprendizaje automático de características:</strong> CNN aprenderían representaciones jerárquicas sin diseño manual</li>
<li><strong>Potencial para mayor desempeño:</strong> Con datasets grandes (>50,000 imágenes), CNN típicamente superan métodos clásicos</li>
<li><strong>Localización espacial:</strong> Técnicas como Grad-CAM permitirían visualizar regiones relevantes</li>
<li><strong>Mayor costo computacional:</strong> Requerirían GPU y tiempos de entrenamiento significativos</li>
</ul>

<h4>Implicaciones Prácticas</h4>

<p>1. <strong>Viabilidad clínica:</strong> Los resultados obtenidos (accuracy >95%, recall >98%) son comparables a tasas de concordancia inter-observador de radiólogos reportadas en literatura (~90-95%).</p>

<p>2. <strong>Sistema de apoyo diagnóstico:</strong> Los modelos desarrollados podrían integrarse como herramienta de segunda opinión o screening inicial en contextos de alta demanda.</p>

<p>3. <strong>Escalabilidad:</strong> La inferencia rápida permite procesar grandes volúmenes de radiografías sin infraestructura costosa.</p>

<p>4. <strong>Contextos con recursos limitados:</strong> Los métodos clásicos son especialmente valiosos en entornos clínicos sin acceso a GPUs o grandes datasets etiquetados.</p>

<h4>Trabajo Futuro</h4>

<p>1. <strong>Implementación de CNN:</strong> Comparar directamente los resultados obtenidos con arquitecturas convolucionales (ResNet, EfficientNet) para validar las ventajas relativas.</p>

<p>2. <strong>Análisis de importancia de características:</strong> Utilizar Random Forest o técnicas de selección para identificar cuáles descriptores aportan mayor información discriminativa.</p>

<p>3. <strong>Validación externa:</strong> Evaluar los modelos en datasets independientes (diferentes hospitales, equipos, poblaciones) para medir generalización real.</p>

<p>4. <strong>Localización de anomalías:</strong> Integrar técnicas de segmentación para identificar espacialmente regiones con infiltrados o consolidaciones.</p>

<p>5. <strong>Ensemble de modelos:</strong> Combinar predicciones de múltiples clasificadores para mejorar robustez.</p>

<p>6. <strong>Optimización de dimensionalidad:</strong> Aplicar PCA o selección de características para reducir redundancia y mejorar eficiencia.</p>

<p>7. <strong>Clasificación multiclase:</strong> Extender el sistema para distinguir entre neumonía bacteriana y viral.</p>

<p>8. <strong>Interfaz clínica:</strong> Desarrollar aplicación web para facilitar adopción en entornos hospitalarios.</p>

<h4>Contribuciones del Proyecto</h4>

<p>Este trabajo ha demostrado que:</p>

<ul>
<li>Los descriptores clásicos de forma y textura siguen siendo herramientas valiosas y competitivas para clasificación de imágenes médicas.</li>
<li>Un pipeline bien diseñado (preprocesamiento → extracción de características → clasificación) puede lograr resultados excepcionales sin necesidad de deep learning.</li>
<li>La combinación estratégica de múltiples tipos de descriptores (HOG, LBP, GLCM, Gabor, momentos de Hu) captura información complementaria que maximiza el poder discriminativo.</li>
<li>SVM con kernel RBF es particularmente efectivo para este tipo de problemas de alta dimensionalidad en el dominio médico.</li>
</ul>

<h3>Reflexión Final</h3>

<p>El proyecto Trabajo 03 ha abordado exitosamente el problema de clasificación automática de radiografías de tórax para diagnóstico de neumonía mediante un enfoque sistemático que abarca desde el preprocesamiento hasta la evaluación comparativa de clasificadores. Los resultados obtenidos (accuracy >95%, F1-score >97% en SVM RBF) validan la hipótesis de que los descriptores clásicos, cuando se combinan apropiadamente y se procesan con clasificadores robustos, pueden alcanzar desempeños clínicamente relevantes.</p>

<p>Este trabajo establece una línea base sólida que puede servir como referencia para comparaciones futuras con métodos de deep learning, y demuestra que las técnicas clásicas de visión por computador mantienen su vigencia y utilidad práctica en escenarios donde la interpretabilidad, eficiencia computacional y trazabilidad son prioritarias sobre la máxima exactitud posible.</p>

<p>La experiencia adquirida en este proyecto refuerza la importancia de entender profundamente cada etapa del pipeline de procesamiento de imágenes médicas, desde el preprocesamiento cuidadoso hasta la selección crítica de descriptores y la evaluación rigurosa con métricas apropiadas al contexto clínico.</p>

<p>---</p>

<h2>Referencias</h2>

<p>1. Goodfellow, I., Bengio, Y., & Courville, A. (2016). <em>Deep Learning</em>. MIT Press. Disponible en: http://www.deeplearningbook.org</p>

<p>2. Gonzalez, R. C., & Woods, R. E. (2018). <em>Digital Image Processing</em> (4th ed.). Pearson.</p>

<p>3. Szeliski, R. (2022). <em>Computer Vision: Algorithms and Applications</em> (2nd ed.). Springer. Disponible en: http://szeliski.org/Book/</p>

<p>4. Dalal, N., & Triggs, B. (2005). Histograms of oriented gradients for human detection. <em>IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 1, 886-893.</p>

<p>5. Ojala, T., Pietikäinen, M., & Mäenpää, T. (2002). Multiresolution gray-scale and rotation invariant texture classification with local binary patterns. <em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em>, 24(7), 971-987.</p>

<p>6. Haralick, R. M., Shanmugam, K., & Dinstein, I. (1973). Textural features for image classification. <em>IEEE Transactions on Systems, Man, and Cybernetics</em>, SMC-3(6), 610-621.</p>

<p>7. He, K., Zhang, X., Ren, S., & Sun, J. (2016). Deep residual learning for image recognition. <em>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 770-778.</p>

<p>8. Simonyan, K., & Zisserman, A. (2015). Very deep convolutional networks for large-scale image recognition. <em>International Conference on Learning Representations (ICLR)</em>.</p>

<p>9. Kermany, D. S., Goldbaum, M., Cai, W., et al. (2018). Identifying medical diagnoses and treatable diseases by image-based deep learning. <em>Cell</em>, 172(5), 1122-1131.e9.</p>

<p>10. Pizer, S. M., Amburn, E. P., Austin, J. D., et al. (1987). Adaptive histogram equalization and its variations. <em>Computer Vision, Graphics, and Image Processing</em>, 39(3), 355-368.</p>


    </div>
</body>
</html>